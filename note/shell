#!bin/bash
exit

for x in {1..20}; do curl cp01-sjws-offline011.cp01/rts/rd?url=$(cat /dev/urandom | tr -dc 'a-zA-Z0-9' | fold -w 32 | head -n 1); done

#
ps axw -o pid,ppid,user,%cpu,vsz,wchan,command | egrep '(nginx|PID)'

[root@www ~]# traceroute [选项与参数] IP
选项与参数：
-n ：可以不必进行主机的名称解析，单纯用 IP ，速度较快！
-U ：使用 UDP 的 port 33434 来进行侦测，这是预设的侦测协议；
-I ：使用 ICMP 的方式来进行侦测；
-T ：使用 TCP 来进行侦测，一般使用 port 80 测试
-w ：若对方主机在几秒钟内没有回声就宣告不治...预设是 5 秒
-p 埠号：若不想使用 UDP 与 TCP 的预设埠号来侦测，可在此改变埠号。
-i 装置：用在比较复杂的环境，如果你的网络接口很多很复杂时，才会用到这个参数；
         举例来说，你有两条 ADSL 可以连接到外部，那你的主机会有两个 ppp，
         你可以使用 -i 来选择是 ppp0 还是 ppp1 啦！
-g 路由：与 -i 的参数相仿，只是 -g 后面接的是 gateway 的 IP 就是了。

# 范例一：侦测本机到 yahoo 去的各节点联机状态
[root@www ~]# traceroute -n tw.yahoo.com
traceroute to tw.yahoo.com (119.160.246.241), 30 hops max, 40 byte packets
 1  192.168.1.254  0.279 ms  0.156 ms  0.169 ms
 2  172.20.168.254  0.430 ms  0.513 ms  0.409 ms
 3  10.40.1.1  0.996 ms  0.890 ms  1.042 ms
 4  203.72.191.85  0.942 ms  0.969 ms  0.951 ms
 5  211.20.206.58  1.360 ms  1.379 ms  1.355 ms
 6  203.75.72.90  1.123 ms  0.988 ms  1.086 ms
 7  220.128.24.22  11.238 ms  11.179 ms  11.128 ms
 8  220.128.1.82  12.456 ms  12.327 ms  12.221 ms
 9  220.128.3.149  8.062 ms  8.058 ms  7.990 ms
10  * * *
11  119.160.240.1  10.688 ms  10.590 ms 119.160.240.3  10.047 ms
12  * * * <==可能有防火墙装置等情况发生所致
这个 traceroute 挺有意思的，这个指令会针对欲连接的目的地之所有 node 进行 UDP 的逾时等待， 例如上面的例子当中，由鸟哥的主机连接到 Yahoo 时，他会经过 12 个节点以上，traceroute 会主动的对这 12 个节点做 UDP 的回声等待，并侦测回复的时间，每节点侦测三次，最终回传像上头显示的结果。 你可以发现每个节点其实回复的时间大约在 50 ms 以内，算是还可以的 Internet 环境了。

比较特殊的算是第 10/12 个，会回传星号的，代表该 node 可能设有某些防护措施，让我们发送的封包信息被丢弃所致。 因为我们是直接透过路由器转递封包，并没有进入路由器去取得路由器的使用资源，所以某些路由器仅支持封包转递， 并不会接受来自客户端的各项侦测啦！此时就会出现上述的问题。因为 traceroute 预设使用 UDP 封包，如果你想尝试使用其他封包， 那么 -I 或 -T 可以试看看啰！

由于目前 UDP/ICMP 的攻击层出不穷，因此很多路由器可能就此取消这两个封包的响应功能。所以我们可以使用 TCP 来侦测呦！ 例如使用同样的方法，透过等待时间 1 秒，以及 TCP 80 埠口的情况下，可以这样做：

[root@www ~]# traceroute -w 1 -n -T tw.yahoo.com


# 范例：找出最大的 MTU 数值
[root@www ~]# ping -c 2 -s 1000 -M do 192.168.1.254


[root@www ~]# dig +trace www.ksu.edu.tw
DiG 9.3.6-P1-RedHat-9.3.6-16.P1.el5 <<>>+trace www.ksu.edu.tw
;; global options:  printcmd
.                       486278  IN      NS      a.root-servers.net.
.                       486278  IN      NS      b.root-servers.net.
....(底下省略)....
# 上面的部分在追踪 . 的服务器，可从 a ~ m.root-servers.net.
;; Received 500 bytes from 168.95.1.1#53(168.95.1.1) in 22 ms

tw.                     172800  IN      NS      ns.twnic.net.
tw.                     172800  IN      NS      a.dns.tw.
tw.                     172800  IN      NS      b.dns.tw.
....(底下省略)....
# 上面的部分在追踪 .tw. 的服务器，可从 a ~ h.dns.tw. 包括 ns.twnic.net.
;; Received 474 bytes from 192.33.4.12#53(c.root-servers.net) in 168 ms

edu.tw.                 86400   IN      NS      a.twnic.net.tw.
edu.tw.                 86400   IN      NS      b.twnic.net.tw.
# 追踪 .edu.tw. 的则有 7 部服务器
;; Received 395 bytes from 192.83.166.11#53(ns.twnic.net) in 22 ms

ksu.edu.tw.             86400   IN      NS      dns2.ksu.edu.tw.
ksu.edu.tw.             86400   IN      NS      dns3.twaren.net.
ksu.edu.tw.             86400   IN      NS      dns1.ksu.edu.tw.
;; Received 131 bytes from 192.83.166.9#53(a.twnic.net.tw) in 22 ms

www.ksu.edu.tw.         3600    IN      A       120.114.100.101
ksu.edu.tw.             3600    IN      NS      dns2.ksu.edu.tw.
ksu.edu.tw.             3600    IN      NS      dns1.ksu.edu.tw.
ksu.edu.tw.             3600    IN      NS      dns3.twaren.net.
;; Received 147 bytes from 120.114.150.1#53(dns2.ksu.edu.tw) in 14 ms

2. 查询 linux.vbird.org 的 SOA 相关信息吧！
[root@www ~]# dig -t soa linux.vbird.org

# 3. 查询 120.114.100.20 的反解信息结果
[root@www ~]# dig -x 120.114.100.20







netstat -[rn]       <==与路由有关的参数
netstat -[antulpc]  <==与网络接口有关的参数

#选项与参数：
#与路由 (route) 有关的参数说明：
-r  ：列出路由表(route table)，功能如同 route 这个指令；
-n  ：不使用主机名与服务名称，使用 IP 与 port number ，如同 route -n
与网络接口有关的参数：
-a  ：列出所有的联机状态，包括 tcp/udp/unix socket 等；
-t  ：仅列出 TCP 封包的联机；
-u  ：仅列出 UDP 封包的联机；
-l  ：仅列出有在 Listen (监听) 的服务之网络状态；
-p  ：列出 PID 与 Program 的檔名；
-c  ：可以设定几秒钟后自动更新一次，例如 -c 5 每五秒更新一次网络状态的显示；

# 范例三：秀出目前已经启动的网络服务
netstat -tulnp

# 范例四：观察本机上头所有的网络联机状态
netstat -atunp

Proto：该联机的封包协议，主要为 TCP/UDP 等封包；
Recv-Q：非由用户程序连接所复制而来的总 bytes 数；
Send-Q：由远程主机所传送而来，但不具有 ACK 标志的总 bytes 数， 意指主动联机 SYN 或其他标志的封包所占的 bytes 数；
Local Address：本地端的地址，可以是 IP (-n 参数存在时)， 也可以是完整的主机名。使用的格是就是『 IP:port 』只是 IP 的格式有 IPv4 及 IPv6 的差异。 如上所示，在 port 22 的接口中，使用的 :::22 就是针对 IPv6 的显示，事实上他就相同于 0.0.0.0:22 的意思。 至于 port 25 仅针对 lo 接口开放，意指 Internet 基本上是无法连接到我本机的 25 埠口啦！
Foreign Address：远程的主机 IP 与 port number
stat：状态栏，主要的状态含有：
ESTABLISED：已建立联机的状态；
SYN_SENT：发出主动联机 (SYN 标志) 的联机封包；
SYN_RECV：接收到一个要求联机的主动联机封包；
FIN_WAIT1：该插槽服务(socket)已中断，该联机正在断线当中；
FIN_WAIT2：该联机已挂断，但正在等待对方主机响应断线确认的封包；
TIME_WAIT：该联机已挂断，但 socket 还在网络上等待结束；
LISTEN：通常用在服务的监听 port ！可使用『 -l 』参数查阅。

 #查看联机的服务
 netstat -atunp | grep 11211 | awk '{print $5}' | grep -Po '.*?:' | sort | uniq

#ftp http://www.freefire.org/articles/ftpexample.php
nc -vv ftp.eckenfels.net 21

filename=$(basename "$fullfile") #获取文件名
extension="${filename##*.}"
filename="${filename%.*}"

sudo !! #没有特定输入sudo命令而运行，将给出没有权限的错误。那么，你不需要重写整个命令，仅仅输入'!!'就可以抓取最后的命令
python -m SimpleHTTPServer  #命令生产一个通过HTTP显示文件夹结构树的简单网页，可以通过浏览器在端口8000访问，直到发出中断信号。
mtr google.com #开始查看mtr运行的主机和google.com直接的网络连接。 ping和traceroute。那对于把两个命令的功能合二为一的mtr命令呢
nl  1.txt #命令，以添加行号的方式来显示。
shuf -n1  #随机数 不重复  这个命令属于 coreutils 包，如果系统没有此命令，请 yum install coreutils 进行安装。
ss #“ss”表示socket统计。这个命令调查socket，显示类似netstat命令的信息。它可以比其他工具显示更多的TCP和状态信息。
curl ifconfig.me #获取外网IP
tree #命令 以树式的格式得到当前文件夹的结构
pstree #这个命令显示当前运行的所有进程及其相关的子进程，输出的是类似‘tree’命令的树状格式




cat > file
> file
:>file

tar -cvf - /home | tar -xvf -

账号:
root UID     0
su root
su - root #这个会有执行权限 并且 . ~/.bashrc 不加-就不会

[root@www ~]# username=${username:-root}

declare -i sum=100+300+50l

#date 格式化
a=`date +%Y%m%d`
date -d "-2 day" "+%Y%m%d %A"   或 date --date="2 days ago" "+%Y%m%d %A"
date +%s  #时间戳

DD 为日，
hh 为小时，
mm 为分钟，
CC 为年份前两位数字，！！！
YY 为年份后两位数字，
ss 为秒数

%a : 星期几 (Sun..Sat)
%A : 星期几 (Sunday..Saturday)
%b : 月份 (Jan..Dec)
%B : 月份 (January..December)
%c : 直接显示日期和时间
%d : 日 (01..31)
%D : 直接显示日期 (mm/dd/yy)
%h : 同 %b
%j : 一年中的第几天 (001..366)
%m : 月份 (01..12)
%U : 一年中的第几周 (00..53) (以 Sunday 为一周的第一天的情形)
%w : 一周中的第几天 (0..6)
%W : 一年中的第几周 (00..53) (以 Monday 为一周的第一天的情形)
%x : 直接显示日期 (mm/dd/yy)
%y : 年份的最后两位数字 (00.99)
%Y : 完整年份 (0000..9999)

# 其中$m 的 $可加 可不加 算数运算
m=$[ m + 1]
m=$(($m + 1))
let m=m+1

#其中$必须添加 乘法需要\转义 最好不要用这种方法
m=`expr $m + 1`
#PS:shell的内部算术运算符无法处理浮点数，所以当需要处理浮点数是，要用到外部工具（如awk）。



nice
renice 优先级

#监控系统程序
vmstat 1 3

#fuser：藉由檔案(或檔案系統)找出正在使用該檔案的程序
fuser -uv .
#找到 /var 底下屬於 FIFO 類型的檔案，並且找出存取該檔案的程序，但試圖刪除該 PID？且『不要』刪除喔！
fuser -ki /var/gdm/.gdmfifo

PS1
\d ：可顯示出『星期 月 日』的日期格式，如："Mon Feb 2"
\H ：完整的主機名稱。舉例來說，鳥哥的練習機為『www.vbird.tsai』
\h ：僅取主機名稱在第一個小數點之前的名字，如鳥哥主機則為『www』後面省略
\t ：顯示時間，為 24 小時格式的『HH:MM:SS』
\T ：顯示時間，為 12 小時格式的『HH:MM:SS』
\A ：顯示時間，為 24 小時格式的『HH:MM』
\@ ：顯示時間，為 12 小時格式的『am/pm』樣式
\u ：目前使用者的帳號名稱，如『root』；
\v ：BASH 的版本資訊，如鳥哥的測試主機版本為 3.2.25(1)，僅取『3.2』顯示
\w ：完整的工作目錄名稱，由根目錄寫起的目錄名稱。但家目錄會以 ~ 取代；
\W ：利用 basename 函數取得工作目錄名稱，所以僅會列出最後一個目錄名。
\# ：下達的第幾個指令。
\$ ：提示字元，如果是 root 時，提示字元為 # ，否則就是 $ 囉～


输入输出流:
0---------标准输入stdin
1---------标准输出stdout
2---------标准错误stderr

ls + > out.txt 输入到屏幕上 不是文件中
ls + 2>out.txt 输入到屏幕 不是文件
ls + 2>&1 out.txt 或 cmd &> out.txt  stderr和stdout同事输入到一个文件

cat *.txt|tee file | more #tee 向文件流输入 同事屏幕也有输出信息
cat *.txt|tee -a file | more # a是 append 否则直接覆盖

3---------只读模式
4---------截断模式
5---------追加模式

exec 3<out.txt;cat <&3
exec 4>out.txt; echo newline >&4;cat out.txt     #截断
exec 5>>out.txt;echo append line >&5             #追加


at:
at -f xx.sh 18:00
at -f mycrontest.sh  10pm tomorrow
at -f mycrontest.sh 2:00 tuesday
at -f mycrontest.sh 2:00 july 11
at -f mycrontest.sh 2:00 next week

atq 查看任务列表
atrm 7  删除任务
at -c 8查看任务

screen:
screen Dms 别名
screen -ls

文件:
访问时间（-atime）用户最后一次访问文件的时间  #ls -lu  或者 ls -l --time=atime
修改时间（-mtime）文件内容最后头一次被修改的时间 #ls -l
变化时间（-ctime）文件数据源（例如权限或所有权）最后一次改变的时间 #ls -lc 或者  ls -l --time=ctime


#循环
for i in {a..z};do echo $i;done;  #是花括号


#if
[ -f $file_var ] 包含正确的文件路径和文件名
[ -x $var ] 是否为可执行文件 为真 true
[ -d $var ] 是否为目录
[ -e $var ] 变量包含的文件是否存在
[ -c $var ] 是否为一个字符设备路径
[ -b $var ] 是否为一个块设备文件路径
[ -w $var ] 文件是否可写
[ -r $var ] 文件是否可读
[ -L $var ] 是否是一个文件链接
if [ -s file  ]    如果文件存在且非空

[ -a FILE ]  如果 FILE 存在则为真。
[ -b FILE ]  如果 FILE 存在且是一个块特殊文件则为真。
[ -c FILE ]  如果 FILE 存在且是一个字特殊文件则为真。
[ -d FILE ]  如果 FILE 存在且是一个目录则为真。
[ -e FILE ]  如果 FILE 存在则为真。
[ -f FILE ]  如果 FILE 存在且是一个普通文件则为真。
[ -g FILE ] 如果 FILE 存在且已经设置了SGID则为真。 [ -h FILE ]  如果 FILE 存在且是一个符号连接则为真。
[ -k FILE ]  如果 FILE 存在且已经设置了粘制位则为真。
[ -p FILE ]  如果 FILE 存在且是一个名字管道(F如果O)则为真。
[ -r FILE ]  如果 FILE 存在且是可读的则为真。
[ -s FILE ]  如果 FILE 存在且大小不为0则为真。
[ -t FD ]  如果文件描述符 FD 打开且指向一个终端则为真。
[ -u FILE ]  如果 FILE 存在且设置了SUID (set user ID)则为真。
[ -w FILE ]  如果 FILE 如果 FILE 存在且是可写的则为真。
[ -x FILE ]  如果 FILE 存在且是可执行的则为真。
[ -O FILE ]  如果 FILE 存在且属有效用户ID则为真。
[ -G FILE ]  如果 FILE 存在且属有效用户组则为真。
[ -L FILE ]  如果 FILE 存在且是一个符号连接则为真。
[ -N FILE ]  如果 FILE 存在 and has been mod如果ied since it was last read则为真。
[ -S FILE ]  如果 FILE 存在且是一个套接字则为真。
[ FILE1 -nt FILE2 ]  如果 FILE1 has been changed more recently than FILE2, or 如果 FILE1 exists and FILE2 does not则为真。
[ FILE1 -ot FILE2 ]  如果 FILE1 比 FILE2 要老, 或者 FILE2 存在且 FILE1 不存在则为真。
[ FILE1 -ef FILE2 ]  如果 FILE1 和 FILE2 指向相同的设备和节点号则为真。
[ -o OPTIONNAME ]  如果 shell选项 “OPTIONNAME” 开启则为真。
[ -z STRING ]  “STRING” 的长度为零则为真。
[ -n STRING ] or [ STRING ]  “STRING” 的长度为非零 non-zero则为真。
[ STRING1 == STRING2 ]  如果2个字符串相同。 “=” may be used instead of “==” for strict POSIX compliance则为真。
[ STRING1 != STRING2 ]  如果字符串不相等则为真。
[ STRING1 < STRING2 ]  如果 “STRING1” sorts before “STRING2” lexicographically in the current locale则为真。
[ STRING1 > STRING2 ]  如果 “STRING1” sorts after “STRING2” lexicographically in the current locale则为真。
[ ARG1 OP ARG2 ] “OP” is one of -eq, -ne, -lt, -le, -gt or -ge. These arithmetic binary operators return true if “ARG1” is equal to, not equal to, less than, less than or equal to, greater than, or greater than or equal to “ARG2”, respectively. “ARG1” and “ARG2” are integers.


If  [  $ANS  ]     等价于  if [ -n $ANS ]

-eq 等于
-ne 不等于
-gt 大于
-lt 小于
-ge 大于等于
-le 小于等于

[[ $str1 = $str2 ]] 判断两个字符串的内容是否相等。在 = 前后有两个空格，没有空格就是赋值关系
[[ -z $str1 ]]      是空字符串返回true
[[ -n $str1 ]]      是非空字符串返回true
if [[ $str = id* ]]
if [[ $str =~ ^id ]]
eg:
fpath="/etc/passwd"
if [ -e $fpath];then
echo File exits;
else
echo Does not exist;
fi


#环境变量
PATH="$PATH:/home/路径"

#常用命令
echo {1..50}
$?    上一个任务的状态 成功为0
!!    执行上一个命令
$$    脚本执行的ID
cd -  回到上一个目录
ls | xargs                                                                                      #排布成一行
ll | tee out.txt | cat -n                                                       #写入out 显示打印 覆盖文本(tee -a 追加文本模式)。
temp_file="/tmp/var.$$"                                                         #.$$会被扩展成当前运行脚本的ID 临时文件
.  ~/.bashrc 读取家目录环境变量

#alias
alias ll='ls -l';echo 'alias ll="ls -l"' >> ~/.bashrc #增加环境变量
alias rm='cp $@ ~/backup; rm $@'                      #删除的时候在备份到目录
alias ll                                              #查看该命令

#cat
echo '123456789' | cat - out.txt                      #拼接 -作为stdin文本的文件名
cat -s out.txt                                                                            #压缩空白行
cat out.txt | tr -s '\n'                                                            #去除空白行
cat out.txt | xargs                                   #将多行文本转成单行文本

#find
find . -not -name "*.exe" -not -name "*.dll" -not -type d
find . -name "*.txt" -print                           #从当前目录开始查找
find . -iname "*.txt" -print                          #忽略大小写
find . -type [df] jack -print                         #目录、文件
find . -type f -user jack                             #查找jack用户文件
find . -type f -user root -exec chown jack {} \;        # {} 代表匹配到的文件 修改拥有者
find . -name "stop.sh" -exec  sh {} \;
find . -name "*.xml" | xargs grep "enable"           #递归查找 文件内容包含
find . -name "*.sh" -print -exec sh  {} /            #递归查找 执行文件
find /data -empty | xargs -i rm -r {}                #删除为空的文件
find ./ -name "*." -exec mv {} {}ts \;               #用shell查询以“.”结尾的文件，并加上后缀“.ts”
find /tmp -mtime +7 -exec rm -rf {} \;               #脚本实现把/tmp/目录下所有创建超过7天的文件删除
find . -name "." -o -prune -type d -print | xargs du -sh  #查看目录大小
find .  ! -name "." -type d -prune -o -type f -name "*.txt" -print
#只是查找当前目录 改变-o右边的搜索项，就可以得到你想要的。记得最后加上-print


find repo/ -exec test -d {}/.svn -o -d {}/.git -o -d {}/CVS ; \
-print -prune

Given the following directory of projects and their associated SCM administrative directories, perform an efficient search for the projects’ roots:

repo/project1/CVS
repo/gnu/project2/.svn
repo/gnu/project3/.svn
repo/gnu/project3/src/.svn
repo/project4/.git

In this example, -prune prevents unnecessary descent into directories that have already been discovered (for example we  do  not  search  project3/src  because  we
already found project3/.svn), but ensures sibling directories (project2 and project3) are found.




grep -A <n> 'keyword' file # 匹配 keyword 的下 n 行
grep -B <n> 'keyword' file # 匹配 keyword 的上 n 行
grep -C <n> 'keyword' file # 匹配 keyword 的上 n 行及下 n 行

#grep
grep "test()" . -R -n                                 #查找 test函数
grep -e "this" -e "line"                              #两个表达式都匹配
grep "test()" . -r --include *.{c,cpp}                #只在.c目录中查找
grep "test()" . -r --exclude *.{c,cpp}                #排除
grep name|grep -v 'grep' | grep -c                    #统计数量
grep -lr "sina" ./ | grep -P "(.*)(\.config$)"        #用一行命令实现：查找当前目录下（含子目录），文件内容中含有sina且文件名以".config"结尾的文件,一句话思路：批量按规则查找文件内容grep

#rename
for file in *.png.jpg; do
  mv "$file" "${file%.png.jpg}.jpg"
done


#rm
rm -rf  file/                                           #删除文件和文件夹下的文件
rm -rf file                                             #注意 没有 / 解除链接档案


#打包 压缩 解压缩
bunzip2 file1.bz2 解压一个叫做 'file1.bz2'的文件
bzip2 file1 压缩一个叫做 'file1' 的文件
gunzip file1.gz 解压一个叫做 'file1.gz'的文件
gzip file1 压缩一个叫做 'file1'的文件
gzip -9 file1 最大程度压缩
rar a file1.rar test_file 创建一个叫做 'file1.rar' 的包
rar a file1.rar file1 file2 dir1 同时压缩 'file1', 'file2' 以及目录 'dir1'
rar x file1.rar 解压rar包
unrar x file1.rar 解压rar包
tar -cvf archive.tar file1 创建一个非压缩的 tarball
tar -cvf archive.tar file1 file2 dir1 创建一个包含了 'file1', 'file2' 以及 'dir1'的档案文件
tar -tf archive.tar 显示一个包中的内容
tar -xvf archive.tar 释放一个包
tar -xvf archive.tar -C /tmp 将压缩包释放到 /tmp目录下
tar -cvfj archive.tar.bz2 dir1 创建一个bzip2格式的压缩包
tar -xvfj archive.tar.bz2 解压一个bzip2格式的压缩包
tar -cvfz archive.tar.gz dir1 创建一个gzip格式的压缩包
tar -xvfz archive.tar.gz 解压一个gzip格式的压缩包
zip file1.zip file1 创建一个zip格式的压缩包
zip -r file1.zip file1 file2 dir1 将几个文件和目录同时压缩成一个zip格式的压缩包
unzip file1.zip 解压一个zip格式压缩包
zcat 1.txt.gz | gzip >> 2.txt.gz #append

#scp
scp   file  username@ip:/var/                         #拷贝 当前的文件到远程IP
scp   username@ip:/var/ .                             #从远程IP的文件 拷贝到当前的目录
scp -r conf/ lib ptc-front.jar work@10.28.0.135:`pwd`



#MD5
md5sum out.txt > file.md5                                                            #计算md5
md5sum -c file.md5                                                                  #验证md5

#base64
echo -n "test@dianxinos.com"|base64                                                 #根据字符产生base64
echo 'AJHKSKB' | tr 'A-Z' 'a-z'                       #将大写转换成小写
echo 123456 | tr '0-9' '9876543210';
echo 876543 | tr '9876543210' '0-9' #加密解密
tr ROT13 详情百度 加密算法

uniq out.txt                                                                        #去除重复
sort out.txt | uniq -c                                                              #统计各行在文本出现的次数
sort out.txt | uniq -d                                                              #找出重复的行

#分割文件
csplit server.log /SERVER/ -n 2 -s {*} -f server -b "%02d.log";rm server server00.log #f文件名 s安静模式 b后缀模式 分割文件
split -b 1024 -d  file # 不指定新名称 默认输出Xaa xab为新文件 详细 man split
split -l 10000 -d file -a 1 newfile_ #a指定输出文件名的后缀，默认为2个 -b 按byte分割 -l 行数分割 -d后缀为数字 默认为字母
ls -al / | split -l 10 - lsroot #重點在那個 - 啦！一般來說，如果需要 stdout/stdin 時，但偏偏又沒有檔案， 有的只是 - 時，那麼那個 - 就會被當成 stdin 或 stdout ～

#合并文件
cat newfile* > story.txt

sort A.txt -o A.txt;sort B.txt -o B.txt
comm A.txt B.txt                                      #第一行只有在A中出现的文件，第二行只有在B中出现的文件 第三行出现相同的行
diff -q A.txt B.txt  #差异
wc -l                                                                                               #统计行数
wc -w 统计单词的数量 wc -c 统计字符数
tree PATH -H http://localhost -o out.html                           #生成html树‘


df -h                                                 #查看磁盘空间
nmap -A -T4 10.18.108.223 #扫描


lynx -dump http://google.com  > page.txt                         #下载网页后提取超链接保存
rsync -auPv 192.168.5.121:/var/daemon/idm/forum/blade/*  /var/daemon/idm/forum/blade/ 备份目录
rsync -avuP --exclude 'logs' --exclude 'result/*' * work@10.28.0.131:/home/work/local/stats/3y_dxbb_stats/ #从本地拷贝到远程 并且排除文件

ln -s /var/目录/ file                                   # 注意 /的区别 有S 是软连接 无S是硬链接 一般都加S 软连接 不会影响到原有数据情况
unlink file                                           #解除连接
host google.com
nslookup google.com                                  #DNS查找
route                                                                                                #显示路由表
Traceroute google.com                                                                #追踪路由请求
ssh user@ip "cat >> ~/.ssh/au" < ~/.ssh/id_rsa.pub   #SSH实现无密码自动登录

环境变量
env
set
locale

ps -ef |grep -v 'grep'| grep testCouchBase | awk '{print $2}' |xargs kill -9

#用noclobber避免覆盖文件
# set -o noclobber
# touch test
# echo "a" > test
#ksh: test: file already exists
# >| test #可以强制覆盖文件
# set +o noclobber
# echo "a" > test
# cat test
#a

此外，shell（这里指ｂａｓｈ）的初始化过程是这样的：
1.bash 检查文件/etc/profile 是否存在
2. 如果存在，bash 就读取该文件，否则，跳过
3.bash 检查主目录下的文件.bash_profile 是否存在。
4. 如果存在，bash 就读取該文件，否则，跳过
5.bash 检查主目录下的.bash_login 是否存在。
6. 如果存在，bash 就读取该文件，否则，跳过
7.bash 检查主目录下的文件.profile 是否存在
8. 如果存在， bash 就读取该文件，否则，跳过。
这些步骤都执行完后，就出现提示符了， ksh 默认提示符是 $.